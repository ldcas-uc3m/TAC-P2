\section{Estudio de PATH}\label{sec:path}


\subsection{Depth-First Search}\label{subsec:dfs}
El algoritmo DFS\supercite{hopcroft1983data} es un algoritmo para recorrer un grafo `en profundidad', y puede ser aplicado a nuestro problema $\mathrm{PATH}(u,v)$ recorriendo el grafo desde el nodo origen ($u$) y comprobando a cada paso si hemos llegado al nodo destino ($v$). En caso de que no lleguemos nunca, no hay camino.

\subsubsection*{Evaluación analítica del algoritmo}
Para analizar correctamente el algoritmo y sacar una cota asintótica superior, debemos de analizar el peor caso, % TODO: citation needed
el cual se da cuando el $u$ es el primer nodo, y el grafo está completamente conectado, excepto el nodo $v$, el cual está exclusivamente conectado al último nodo.



\subsection*{Evaluación empírica}

Para evaluar el comportamiento del algoritmo creado y comprobar si las conclusiones desarrolladas en la evaluación anaítica son correctas se lleva acabo una serie de tests, tomando la probabilidad de encontrar



\plotperformance{DFS}



\subsection{Floyd-Warshall}\label{subsec:fw}

\subsubsection*{Evaluación analítica del algoritmo}

Para analizar el coste computacional del algoritmo desarrollado, se puede dividir en tres secciones claramente diferenciadas para luego sumar sus costes y obtener un total, siendo dichas secciones: 
\begin{itemize}
    \item \textbf{Inicialización del Algoritmo}: Inicializar el algoritmo leyendo los parámetros e inicializar los dos nodos a computar el coste es de 7, ya que se trata únicamente de inicialización de variables y una comparación 'IF'.
    
    \item \textbf{Inicialización de matriz de distancias}: Esta sección del algoritmo cuenta con 2 bucles anidados que calculan la matriz de unos y ceros que indican que nodos se encuentran directamente conectados.
    \begin{itemize}
        \item \textbf{Bucle externo (u)}: Itera a través de cada nodo que actúa como un nodo intermedio en los caminos posibles, con un coste de $2n$ puesto que se modifica el valor de dos variables.
        \item \textbf{Bucle externo (v)}: Itera sobre todos los nodos posibles como nodo inicial, con un coste de n. En su interior el bucle consta de dos modificaciones de variables, y varias comparaciones 'IF' teniendo en el peor caso la comparación un coste de 3, por lo que el coste total del bucle sería de $5n$.
    \end{itemize}
    El costo de esta sección del algoritmo sería de un total de $10n^2$

    \item \textbf{Cálculo de la distancia entre nodos}: Itera sobre todos los nodos posibles como nodo final.
    \begin{itemize}
        \item \textbf{Bucle externo (k)}: Itera a través de cada nodo que actúa como un nodo intermedio en los caminos posibles, con un coste de n.
        \item \textbf{Bucle medio (i)}: Itera sobre todos los nodos posibles como nodo inicial, con un coste de $n$.
        \item \textbf{Bucle interno (j)}: Itera sobre todos los nodos posibles como nodo final, con un coste de n. Cuenta con una comparación 'IF' de coste 2 por lo que el coste total de este bucles sería de $2n$.
    \end{itemize}
    El costo de esta sección sería de un total de $2n^3$
    
\end{itemize}

Si se toma el costo de cada una de las tres secciones que componen el algoritmo, el costo total del algoritmo sería:
\begin{equation}
    T_{\mathrm{FW}}(n) = 2n^3 + 10n^2 + 7
\end{equation}

La complejidad temporal del algoritmo de Floyd-Warshall, viene dada por los tres bucles anidados donde se calcula la distancia entre nodos  siendo esta:
\begin{equation}
    O_{\mathrm{FW}}(n^3) 
\end{equation}

\subsection*{Evaluación empírica}

Para evaluar el comportamiento del algoritmo creado y comprobar si las conclusiones desarrolladas en la evaluación analítica son correctas se lleva acabo una batería de pruebas con diferentes valores tanto para una misma $n$ con diferentes $p$ como a la inversa, a fin de comprobar como afecta cada una al rendimiento.

\plotperformance{FW}

Se observa que el costo computacional definido por T(n) se corresponde con los resultados obtenidos ya que se observa en la gráfica que el comportamiento que sigue el algoritmo se aproxima a ser cúbico. Se observa también que la variación de $p$, la probabilidad de que dos nodos se encuentren conectados, apenas  afecta a los resultados de $T(n)$.

Esto es coherente con la evaluación analítica realizada ya que para Floyd-Warshall la complejidad temporal viene determinada por el numero de nodos y no tanto por la densidad del propio grafo, ya que los bucles se ejecutan para cada nodo y no únicamente ara los nodos conectados, lo que muestra que es un algoritmo adecuado para encontrar caminos entre nodos independientemente de la densidad del grafo dado.

Por otro lado se observando que la variación del tiempo para computar una misma $n$ en función de $p$ es mínima y esta apenas tiene influencia ya que la variación es de pocas decenas de microsegundos
