\section{Estudio de PATH}\label{sec:path}


\subsection{Depth-First Search}\label{subsec:dfs}
El algoritmo DFS\supercite{hopcroft1983data} es un algoritmo para recorrer un grafo `en profundidad', y puede ser aplicado a nuestro problema $\mathrm{PATH}(u,v)$ recorriendo el grafo desde el nodo origen ($u$) y comprobando a cada paso si hemos llegado al nodo destino ($v$). En caso de que no lleguemos nunca, no hay camino.

\subsubsection*{Evaluación analítica del algoritmo}
Para analizar correctamente el algoritmo y sacar una cota asintótica superior, debemos de analizar el peor caso, % TODO: citation needed
el cual se da cuando el $u$ es el primer nodo, y el grafo está completamente conectado, excepto el nodo $v$, el cual está exclusivamente conectado al último nodo.

Para realizar la evaluación  analítica del algoritmo, se divide este en dos secciones a fin de determinar el costo de cada una, ya que se trata de funciones.

\begin{itemize}
    \item \textbf{Inicialización del Algoritmo}: Esta función (\texttt{path\_dfs}) cuenta con la inicialización de las variables correspondientes a cada uno de los nodos argumento, así como la inicialización de la variable de nodos resultados y la llamada a la función que calculará la distancia DFS, por ello su coste es de 4.

    \item \textbf{Algoritmo DFS}: Esta función (\texttt{\_path\_dfs}) cuenta con una comparación \texttt{IF} y con una inicialización de variable cuyo coste total es de 3. En su interior se encuentra un bucle con dos comparaciones \texttt{IF} en su interior que suman coste 4, y una llamada recursiva al propio bucle, por ello su coste sería de $n^k$.
\end{itemize}

Una vez computada el coste de cada función por separado se puede obtener el coste total del algoritmo en el pero caso siendo:
\begin{equation}
    T_{\mathrm{DFS}}(n) = 4n^k+4
\end{equation}

La complejidad temporal del algoritmo de Floyd-Warshall, viene dada por los tres bucles anidados donde se calcula la distancia entre nodos  siendo esta:
\begin{equation}
    O_{\mathrm{DFS}}(n^k) 
\end{equation}

\subsection*{Evaluación empírica}

Para evaluar el comportamiento del algoritmo creado y comprobar si las conclusiones desarrolladas en la evaluación analítica son correctas se lleva a cabo una batería de pruebas con diferentes valores tanto para una misma $n$ con diferentes $p$ como a la inversa, a fin de comprobar como afecta cada una al rendimiento.

\plotperformance{DFS}

Se observa claramente en la gráfica que para grafos con densidades extremas, ya sean muy conectados o totalmente conectados, el tiempo de computación es notablemente menor que para grafos con densidades medias.

Esto se debe a que en los grafos con densidades bajas, el algoritmo encuentra rápido aquellos caminos por lo que no es posible continuar con la búsqueda, ya que los nodos tiene pocas conexiones  En el caso de grafos de alta densidad o totalmente conectados también el algoritmo encontrará rápido un camino entre nodos, ya que habrá pocos o nulos caminos sin salida.

Por otro lado en grafos de densidad media, el algoritmo tendrá que probar con múltiples caminos que pueden ser más largos pese a no conducir al objetivo para luego tener que probar nuevos caminos.
Esto se observa también claramente en la segunda gráfica donde para una misma $n$ a medida que $p$ aumenta el tiempo de computación aumenta hasta llegar a un pico entre $p=0.5$ y $p=0.6$ donde se crearán grafos de densidad media, para luego descender a medida que $p$ aumenta hasta llegar al grafo totalmente conectado.



\subsection{Floyd-Warshall}\label{subsec:fw}

\subsubsection*{Evaluación analítica del algoritmo}

Para analizar el coste computacional del algoritmo desarrollado, se puede dividir en tres secciones claramente diferenciadas para luego sumar sus costes y obtener un total, siendo dichas secciones: 
\begin{itemize}
    \item \textbf{Inicialización del Algoritmo}: Inicializar el algoritmo leyendo los parámetros e inicializar los dos nodos a computar el coste es de 7, ya que se trata únicamente de inicialización de variables y una comparación 'IF'.
    
    \item \textbf{Inicialización de matriz de distancias}: Esta sección del algoritmo cuenta con 2 bucles anidados que calculan la matriz de unos y ceros que indican que nodos se encuentran directamente conectados.
    \begin{itemize}
        \item \textbf{Bucle externo (u)}: Itera a través de cada nodo que actúa como un nodo intermedio en los caminos posibles, con un coste de $2n$ puesto que se modifica el valor de dos variables.
        \item \textbf{Bucle externo (v)}: Itera sobre todos los nodos posibles como nodo inicial, con un coste de n. En su interior el bucle consta de dos modificaciones de variables, y varias comparaciones 'IF' teniendo en el peor caso la comparación un coste de 3, por lo que el coste total del bucle sería de $5n$.
    \end{itemize}
    El costo de esta sección del algoritmo sería de un total de $10n^2$

    \item \textbf{Cálculo de la distancia entre nodos}: Itera sobre todos los nodos posibles como nodo final.
    \begin{itemize}
        \item \textbf{Bucle externo (k)}: Itera a través de cada nodo que actúa como un nodo intermedio en los caminos posibles, con un coste de n.
        \item \textbf{Bucle medio (i)}: Itera sobre todos los nodos posibles como nodo inicial, con un coste de $n$.
        \item \textbf{Bucle interno (j)}: Itera sobre todos los nodos posibles como nodo final, con un coste de n. Cuenta con una comparación `IF' de coste 2 por lo que el coste total de este bucle sería de $2n$.
    \end{itemize}
    El costo de esta sección sería de un total de $2n^3$
    
\end{itemize}

Si se toma el costo de cada una de las tres secciones que componen el algoritmo, el costo total del algoritmo sería:
\begin{equation}
    T_{\mathrm{FW}}(n) = 2n^3 + 10n^2 + 7
\end{equation}

La complejidad temporal del algoritmo de Floyd-Warshall, viene dada por los tres bucles anidados donde se calcula la distancia entre nodos  siendo esta:
\begin{equation}
    O_{\mathrm{FW}}(n^3) 
\end{equation}

\subsection*{Evaluación empírica}

Para evaluar el comportamiento del algoritmo creado y comprobar si las conclusiones desarrolladas en la evaluación analítica son correctas se lleva a cabo una batería de pruebas con diferentes valores tanto para una misma $n$ con diferentes $p$ como a la inversa, a fin de comprobar como afecta cada una al rendimiento.

\plotperformance{FW}

Se observa que el costo computacional definido por T(n) se corresponde con los resultados obtenidos, ya que se observa en la gráfica que el comportamiento que sigue el algoritmo se aproxima a ser cúbico. Se observa también que la variación de $p$, la probabilidad de que dos nodos se encuentren conectados, apenas  afecta a los resultados de $T(n)$.

Esto es coherente con la evaluación analítica realizada, ya que para Floyd-Warshall la complejidad temporal viene determinada por el número de nodos y no tanto por la densidad del propio grafo, ya que los bucles se ejecutan para cada nodo y no únicamente ara los nodos conectados, lo que muestra que es un algoritmo adecuado para encontrar caminos entre nodos independientemente de la densidad del grafo dado.

Por otro lado se ha observando que la variación del tiempo para computar una misma $n$ en función de $p$ es mínima y esta apenas tiene influencia, ya que la variación es de pocas decenas de microsegundos
